{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d2fc3138",
   "metadata": {},
   "source": [
    "# Double-Difference Earthquake Location\n",
    "In this tutorial, we go through the powerful earthquake double-difference location method, to better convey the core components of the method, we simplify the model to avoid it runs too complicated to be understood.\n",
    "1. Use one-layer homogeneous velocity model to get rid of complicated ray-tracing.\n",
    "2. Use 2-D X-Z plane rather than 3-D X-Y-Z to decrease complexity\n",
    "3. Use P arrivals only\n",
    "After this tutorial, besides the understanding of key concepts in Double-Difference location, you will also find that model expand from 2-D to 3-D, from one-layer to multi-layers, from P to P&S arrivals, the key processing remains the same.\n",
    "\n",
    "You are strongly encouraged to play around codes in this tutorial and introduce to others, you will find your understanding will be enhanced dramatically during thess process.\n",
    "\n",
    "### Authors\n",
    "\n",
    "**ZI, Jinping**, Earth Science System Program, CUHK\n",
    "\n",
    "**SONG, Zilin**, Earth Science System Program, CUHK\n",
    "\n",
    "### Testers\n",
    "\n",
    "**XIA, Zhuoxuan**, Earth Science System Program, CUHK\n",
    "\n",
    "**SUN, Zhangyu**, Earth Science System Program, CUHK"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d35d790",
   "metadata": {},
   "source": [
    "## Preparation for Environment and Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e78b75e-0c0a-49b2-ac43-6948435b0bc3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import time\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.patches import Polygon\n",
    "from scipy.sparse.linalg import lsqr\n",
    "from scipy.sparse import csc_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf8d8a35",
   "metadata": {},
   "outputs": [],
   "source": [
    "def iter_loc(hyc_loop,stas,d,V,niter=10):\n",
    "    \"\"\"\n",
    "    Iterative aboslute earthquake location using least-square method,\n",
    "    refer to absolute earthquake location python tutorial.\n",
    "    Parameters:\n",
    "    | hyc_loop: hypocenter for iteration\n",
    "    |     stas: array containing station information\n",
    "    |        d: the observed arrival time\n",
    "    |        V: the velocity\n",
    "    |    niter: maximum number of iteration\n",
    "    \"\"\"\n",
    "    k = 0\n",
    "    while k <= niter:\n",
    "        dcal = np.zeros((d.shape[0],1))\n",
    "        for i in range(d.shape[0]):\n",
    "            dx = stas[i,0]-hyc_loop[0]\n",
    "            dz = stas[i,1]-hyc_loop[1]\n",
    "            dcal[i,0] = np.sqrt(dx**2+dz**2)/V+hyc_loop[2]\n",
    "        delta_d = d - dcal\n",
    "        e2 = 0 \n",
    "        for i in range(delta_d.shape[0]):\n",
    "            e2 += delta_d[i,0]**2\n",
    "        print(f\"Iteration {format(k,'2d')} square error: \",format(e2,'13.8f'))\n",
    "\n",
    "        # >>>>> Build G matrix >>>>>>\n",
    "        G = np.zeros((d.shape[0],3))\n",
    "        G[:,2]=1\n",
    "        for i in range(d.shape[0]):\n",
    "            for j in range(2):\n",
    "                denomiter = np.sqrt((hyc_loop[0]-stas[i,0])**2+(hyc_loop[1]-stas[i,1])**2)\n",
    "                G[i,j]=(hyc_loop[j]-stas[i,j])/denomiter/V\n",
    "\n",
    "        # >>>>> Invert the m value >>>>        \n",
    "        GTG = np.matmul(G.T,G)\n",
    "        GTG_inv = np.linalg.inv(GTG)\n",
    "        GTG_inv_GT = np.matmul(GTG_inv,G.T)\n",
    "        delta_m = np.matmul(GTG_inv_GT,delta_d)\n",
    "\n",
    "        # >>>>> Update the hypocenter loop >>>>>\n",
    "        hyc_loop = np.add(hyc_loop,delta_m.ravel())\n",
    "        k = k+1\n",
    "           \n",
    "        # >>>>> End the loop if error is small >>>>>\n",
    "        if e2<0.00000001:\n",
    "            break\n",
    "    \n",
    "    sigma_d = np.std(delta_d)\n",
    "    var = sigma_d**2*(d.shape[0])/(d.shape[0]-4)\n",
    "    sigma_m2 = var * GTG_inv\n",
    "    return hyc_loop, sigma_m2\n",
    "\n",
    "def present_loc_results(hyc,sig_square=None,std_fmt='.2f'):\n",
    "    \"\"\"\n",
    "    Print earthquake location results, refer to absolute earthquake location\n",
    "    for reference\n",
    "    Parameters:\n",
    "    |       hyc: hypocenter\n",
    "    |sig_square: squared convariance\n",
    "    \"\"\"\n",
    "    _x = format(np.round(hyc[0],4),format(\"6.2f\"))\n",
    "    _z = format(np.round(hyc[1],4),format(\"6.2f\"))\n",
    "    _t = format(np.round(hyc[2],4),format(\"6.2f\"))\n",
    "    if not isinstance(sig_square,np.ndarray):\n",
    "        print(\"x = \",_x,\" km\")\n",
    "        print(\"z = \",_z,\" km\")\n",
    "        print(\"t = \",_t,\" s\")\n",
    "    else:\n",
    "        stdx = sig_square[0,0]**0.5\n",
    "        _stdx = format(np.round(stdx,4),std_fmt)\n",
    "        stdz = sig_square[1,1]**0.5\n",
    "        _stdz = format(np.round(stdz,4),std_fmt)\n",
    "        stdt = sig_square[2,2]**0.5\n",
    "        _stdt = format(np.round(stdt,4),std_fmt)\n",
    "        print(\"x = \",_x,\"±\",_stdx,\" km\")\n",
    "        print(\"z = \",_z,\"±\",_stdz,\" km\")\n",
    "        print(\"t = \",_t,\"±\",_stdt,\" s\")\n",
    "        \n",
    "def matrix_show(*args,**kwargs):\n",
    "    \"\"\"\n",
    "    Show matrix values in grids shape\n",
    "    Parameters:cmap=\"cool\",gridsize=0.6,fmt='.2f',label_data=True\n",
    "    \"\"\"\n",
    "    ws = []\n",
    "    H = 0\n",
    "    str_count = 0\n",
    "    ndarr_count = 0\n",
    "    new_args = []\n",
    "    for arg in args:\n",
    "        if isinstance(arg,str):\n",
    "            new_args.append(arg)\n",
    "            continue\n",
    "        if isinstance(arg,list):\n",
    "            arg = np.array(arg)\n",
    "        if len(arg.shape)>2:\n",
    "            raise Exception(\"Only accept 2D array\")\n",
    "        if len(arg.shape) == 1:\n",
    "            n = arg.shape[0]\n",
    "            tmp = np.zeros((n,1))\n",
    "            tmp[:,0] = arg.ravel()\n",
    "            arg = tmp\n",
    "        h,w = arg.shape\n",
    "        if h>H:\n",
    "            H=h\n",
    "        ws.append(w)\n",
    "        new_args.append(arg)\n",
    "        ndarr_count += 1\n",
    "    W = np.sum(ws)+len(ws)    # text+matrix+text+...+matrix+text\n",
    "    if W<0:\n",
    "        raise Exception(\"No matrix provided!\")\n",
    "        \n",
    "    fmt = '.2f'\n",
    "    grid_size = 0.6\n",
    "    cmap = 'cool'\n",
    "    label_data = True\n",
    "    for arg in kwargs:\n",
    "        if arg == \"fmt\":\n",
    "            fmt = kwargs[arg]\n",
    "        if arg == 'grid_size':\n",
    "            grid_size = kwargs[arg]\n",
    "        if arg == 'cmap':\n",
    "            cmap = kwargs[arg]\n",
    "        if arg == 'label_data':\n",
    "            label_data = kwargs[arg]\n",
    "    fig = plt.figure(figsize=(W*grid_size,H*grid_size))\n",
    "    gs = fig.add_gridspec(nrows=H,ncols=W)\n",
    "    \n",
    "    wloop = 0\n",
    "    matrix_id = 0\n",
    "    for arg in new_args:\n",
    "        if isinstance(arg,str):\n",
    "            ax = fig.add_subplot(gs[0:H,wloop-1:wloop])\n",
    "            ax.axis(\"off\")\n",
    "            ax.set_xlim(0,1)\n",
    "            ax.set_ylim(0,H)\n",
    "            ax.text(0.5,H/2,arg,horizontalalignment='center',verticalalignment='center')\n",
    "        if isinstance(arg,np.ndarray):\n",
    "            h,w = arg.shape\n",
    "            hlow = int(np.round((H-h+0.01)/2))        # Find the height grid range\n",
    "            hhigh = hlow+h\n",
    "            wlow = wloop\n",
    "            whigh = wlow+w\n",
    "#            print(\"H: \",H,hlow,hhigh,\"; W \",W,wlow,whigh)\n",
    "            ax = fig.add_subplot(gs[hlow:hhigh,wlow:whigh])\n",
    "            \n",
    "            plt.pcolormesh(arg,cmap=cmap)\n",
    "            for i in range(1,w):\n",
    "                plt.axvline(i,color='k',linewidth=0.5)\n",
    "            for j in range(1,h):\n",
    "                plt.axhline(j,color='k',linewidth=0.5)\n",
    "            if label_data:\n",
    "                for i in range(h):\n",
    "                    for j in range(w):\n",
    "                        plt.text(j+0.5,i+0.5,format(arg[i,j],fmt),\n",
    "                                 horizontalalignment='center',\n",
    "                                 verticalalignment='center')\n",
    "            plt.xlim(0,w)\n",
    "            plt.ylim([h,0])\n",
    "            plt.xticks([])\n",
    "            plt.yticks([])\n",
    "            wloop+=w+1\n",
    "            matrix_id+=1\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2fa83af6",
   "metadata": {},
   "source": [
    "## Basic parameters\n",
    "Set up station array, earthquake true location, wave-velocity and generate synthetic arrival time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8cb23dd9",
   "metadata": {},
   "outputs": [],
   "source": [
    "stas =np.array([[-20,0],[-14,0],[-8,0],[0,0],[8,0],[14,0],[20,0]]) # Station \n",
    "stas =np.array([[-19,0],[-13,0],[-7,0],[0,0],[8,0],[14,0],[20,0]]) # Station\n",
    "hyc1_true = np.array([-1,8,0])\n",
    "Vtrue = 5\n",
    "nsta = stas.shape[0]\n",
    "dobs1 = np.zeros((nsta,1))\n",
    "for i in range(dobs1.shape[0]):\n",
    "    dx = stas[i,0]-hyc1_true[0]\n",
    "    dz = stas[i,1]-hyc1_true[1]\n",
    "    dobs1[i,0] = np.sqrt(dx**2+dz**2)/Vtrue+hyc1_true[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8bd8d68d",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Plot event, stations, and rays\n",
    "fig,ax= plt.subplots(1,1)\n",
    "plt.plot(hyc1_true[0],hyc1_true[1],'r*',ms=10,label='Event 1')\n",
    "plt.plot(stas[:,0],stas[:,1],'b^',ms=10,label=\"Station\")\n",
    "for sta in stas:\n",
    "    plt.plot([hyc1_true[0],sta[0]],[hyc1_true[1],sta[1]],'k-')\n",
    "\n",
    "# Add grey background\n",
    "nodes = [[-25,10],[25,10],[25,0],[-25,0]]\n",
    "p = Polygon(nodes,facecolor='lightgrey')\n",
    "for i in range(stas.shape[0]):\n",
    "    sta = stas[i]\n",
    "    plt.text(sta[0]-3,sta[1]-0.5,'Sta '+str(i))\n",
    "plt.gca().add_patch(p)\n",
    "\n",
    "# Set up plot elements\n",
    "plt.xlim([-25,25])\n",
    "plt.ylim([10,-2])\n",
    "plt.xlabel(\"X (km)\")\n",
    "plt.ylabel(\"Depth (km)\")\n",
    "plt.title(\"Model\")\n",
    "plt.legend();"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "967f95aa",
   "metadata": {},
   "source": [
    "# Aboslute Earthquake Location\n",
    "## Initial trial location\n",
    "The station which records the earliest waveform is closest to the hypocenter, so it is reasonable to start iteration: \n",
    "1. The same x and y with the cloest station;\n",
    "2. Initial depth at 5 km;\n",
    "3. Initial origin time 1 sec before the earliest arrival;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a69f9f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "idx = np.argmin(dobs1)       # The index of station\n",
    "dmin = np.min(dobs1)         # The minimum arrival time\n",
    "\n",
    "hyc1_init = np.zeros(3);      # Init array\n",
    "hyc1_init[0] = stas[idx,0];   # Set the same x,y with station\n",
    "hyc1_init[1] = 5;             # Set initial depth 5 km\n",
    "hyc1_init[2] = dmin-1;        # Set initial event time 1s earlier than arrival\n",
    "print(\"Initial trial parameters \",\"x: \",hyc1_init[0],\"km; \",\"z: \",hyc1_init[1],\"km; \",\"t: \", format(hyc1_init[2],'.4f')+\" s\")\n",
    "hyc1_loop = hyc1_init.copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c774482",
   "metadata": {},
   "source": [
    "We can also define a function to get the initial location"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "635b2f05",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_init_loc(dobs,stas,depth=5,gap_time=1):\n",
    "    \"\"\"\n",
    "    Get initial earthquake location\n",
    "    \"\"\"\n",
    "    dmin = np.min(dobs)         # The minimum arrival time\n",
    "    idx = np.argmin(dobs)       # The index of observation\n",
    "\n",
    "    hyc_init = np.zeros(3);      # Init array\n",
    "    hyc_init[0] = stas[idx,0];   # Set the same x,y with station\n",
    "    hyc_init[1] = depth;             # Set initial depth 5 km\n",
    "    hyc_init[2] = dmin-gap_time;        # Set initial event time 1s earlier than arrival\n",
    "    print(\"Initial trial parameters \",\"x: \",hyc_init[0],\"km; \",\"z: \",hyc_init[1],\"km; \",\"t: \", format(hyc_init[2],'.4f')+\" s\")\n",
    "    return hyc_init"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "981b6b24",
   "metadata": {},
   "outputs": [],
   "source": [
    "hyc1_init = get_init_loc(dobs1,stas)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8117bc47",
   "metadata": {},
   "source": [
    "For the knowledge of iteration location, please refer to the tutorial of Earthquake Absolute Location."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13834033",
   "metadata": {},
   "outputs": [],
   "source": [
    "hyc1_abs, sigma_m2 = iter_loc(hyc1_loop,stas,dobs1,Vtrue)\n",
    "present_loc_results(hyc1_abs,sigma_m2,std_fmt='.4f')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5f3880d",
   "metadata": {},
   "source": [
    "## Velocity Error\n",
    "In the calculation above, we use the true velocity (**Vtrue**) to conduct the inversion. However, in reality, the velocity we measured more or less different from the true velocity, thus leading to some bias.\n",
    "\n",
    "## Exercise (1 min)\n",
    "Try to use other velocity values to conduct the inversion and check the results, what features do you find?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13b5def1",
   "metadata": {},
   "outputs": [],
   "source": [
    "Vp = 4.8\n",
    "hyc1_abs, sigma_m2 = iter_loc(hyc1_init,stas,dobs1,Vp)\n",
    "present_loc_results(hyc1_abs,sigma_m2,std_fmt='.4f')\n",
    "print(\"True location (hyc1_true) \",\"x: \",hyc1_true[0],\"km; \",\"z: \",hyc1_true[1],\"km; \",\"t: \", format(hyc1_true[2],'.4f')+\" s\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b060135",
   "metadata": {},
   "source": [
    "## Station Delay\n",
    "\n",
    "In near surface, the material velocity where stations are located might vary and lead to influence on the travel time, we call it **Station delay**. \n",
    "\n",
    "The **River sediments** are generally composed by not fully consolidated materials, their velocities are therefore low. A lower velocity will lead to a longer travel time, thus the actual arrival time will be later than estimated, here we call it **Positive delay**.\n",
    "\n",
    "The **Granite** is igneous rock, its density is high with fast velocity. A higher velocity will lead to a shorter travel time, thus the actual arrival time will be earlier than estimated, we call it\n",
    "**Negative delay**.\n",
    "\n",
    "In this tutorial, we set value of 0.05s for positive delay and -0.05s for negative delay."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "690ec043",
   "metadata": {},
   "outputs": [],
   "source": [
    "semix = np.linspace(-1,1,101)\n",
    "semiy = np.sqrt(1-semix**2)\n",
    "semixy = np.zeros((101,2))\n",
    "semixy[:,0] = semix\n",
    "semixy[:,1] = semiy*0.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "004e5cf1",
   "metadata": {},
   "outputs": [],
   "source": [
    "for sta in stas:\n",
    "    plt.plot([hyc1_true[0],sta[0]],[hyc1_true[1],sta[1]],'k')\n",
    "station, = plt.plot(stas[:,0],stas[:,1],'b^',ms=10,label=\"Station\")\n",
    "event, = plt.plot(hyc1_true[0],hyc1_true[1],'r*',ms=10,label='Event 1')\n",
    "nodes = [[-25,10],[25,10],[25,0],[-25,0]]\n",
    "p = Polygon(nodes,facecolor='lightgrey')\n",
    "plt.gca().add_patch(p)\n",
    "for sta in stas[:3]:\n",
    "    p_pos = Polygon(sta+semixy*2,facecolor='cyan')\n",
    "    plt.gca().add_patch(p_pos)\n",
    "for sta in stas[4:]:\n",
    "    p_neg = Polygon(sta+semixy*2,facecolor='yellow')\n",
    "    plt.gca().add_patch(p_neg)\n",
    "for i in range(stas.shape[0]):\n",
    "    sta = stas[i]\n",
    "    plt.text(sta[0]-3,sta[1]-0.5,'Sta '+str(i))\n",
    "\n",
    "plt.xlabel(\"X (km)\")\n",
    "plt.ylabel(\"Depth (km)\")\n",
    "plt.xlim([-25,25])\n",
    "plt.ylim([10,-2])\n",
    "plt.legend([station,event,p_pos,p_neg],[\"Station\",\"Event 1\",\"River sediments\",\"Granite\"]);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6bad9844",
   "metadata": {},
   "outputs": [],
   "source": [
    "stas_delay = np.zeros((nsta,1))\n",
    "stas_delay[:,0]= [0.05,0.05,0.05,0,-0.05,-0.05,-0.05]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8bc7fade",
   "metadata": {},
   "source": [
    "### Conduct inversion with delayed data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94115aaf",
   "metadata": {},
   "outputs": [],
   "source": [
    "dobs1_delay = dobs1 + stas_delay\n",
    "hyc1_abs_delay, sigma_m2 = iter_loc(hyc1_init,stas,dobs1_delay,Vp)\n",
    "present_loc_results(hyc1_abs_delay,sigma_m2)\n",
    "print(\"True location (hyc1_true) \",\"x: \",hyc1_true[0],\"km; \",\"z: \",hyc1_true[1],\"km; \",\"t: \", format(hyc1_true[2],'.4f')+\" s\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5cd675d",
   "metadata": {},
   "source": [
    "## The second event\n",
    "Now we consider a second event occurred close to the first event"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2229c38",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "hyc2_true = [1,8.3,1]\n",
    "# Plot event, stations, and rays\n",
    "fig,ax= plt.subplots(1,1)\n",
    "\n",
    "# Add grey background\n",
    "nodes = [[-25,10],[25,10],[25,0],[-25,0]]\n",
    "p = Polygon(nodes,facecolor='lightgrey')\n",
    "plt.gca().add_patch(p)\n",
    "\n",
    "# Plot events\n",
    "plt.plot(hyc1_true[0],hyc1_true[1],'r*',ms=10,label='Event 1')\n",
    "plt.plot(hyc2_true[0],hyc2_true[1],'g*',ms=10, label=\"Event 2\")\n",
    "\n",
    "\n",
    "# Plot stations and rays\n",
    "plt.plot(stas[:,0],stas[:,1],'b^',ms=10,label=\"Station\")\n",
    "for i in range(stas.shape[0]):\n",
    "    sta = stas[i]\n",
    "    plt.text(sta[0]-2,sta[1]-0.5,'Sta '+str(i))\n",
    "    plt.plot([hyc1_true[0],sta[0]],[hyc1_true[1],sta[1]],'k-')\n",
    "    plt.plot([hyc2_true[0],sta[0]],[hyc2_true[1],sta[1]],'w-')\n",
    "    if i<3:\n",
    "        p_pos = Polygon(sta+semixy*2,facecolor='cyan')\n",
    "        plt.gca().add_patch(p_pos)\n",
    "    if i>3:\n",
    "        p_neg = Polygon(sta+semixy*2,facecolor='yellow')\n",
    "        plt.gca().add_patch(p_neg)\n",
    "\n",
    "# Set up plot elements\n",
    "plt.xlim([-25,25])\n",
    "plt.ylim([10,-2])\n",
    "plt.xlabel(\"X (km)\")\n",
    "plt.ylabel(\"Depth (km)\")\n",
    "plt.title(\"Model\")\n",
    "plt.legend();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3cb1b1ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "dobs2 = np.zeros((nsta,1))\n",
    "for i in range(dobs2.shape[0]):\n",
    "    dx = stas[i,0]-hyc2_true[0]\n",
    "    dz = stas[i,1]-hyc2_true[1]\n",
    "    dobs2[i,0] = np.sqrt(dx**2+dz**2)/Vtrue+hyc2_true[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "044a59ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "hyc2_init = get_init_loc(dobs2,stas)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0fbd0980",
   "metadata": {},
   "outputs": [],
   "source": [
    "dobs2_delay = dobs2 + stas_delay\n",
    "hyc2_abs, sigma_m2 = iter_loc(hyc2_init,stas,dobs2_delay,Vtrue)\n",
    "present_loc_results(hyc2_abs,sigma_m2)\n",
    "print(\"True location (hyc2_true) \",\"x: \",hyc2_true[0],\"km; \",\"z: \",hyc2_true[1],\"km; \",\"t: \", format(hyc2_true[2],'.4f')+\" s\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a206890",
   "metadata": {},
   "source": [
    "## Add Picking Noise\n",
    "please refer to Earthquake Absolute Location tutorial for more information of add picking noise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14e966c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "mu = 0\n",
    "sigma = 0.1\n",
    "np.random.seed(252)\n",
    "errors = np.random.normal(mu,sigma,size=(nsta,1))\n",
    "dobs1_delay_noise = dobs1_delay+errors\n",
    "np.random.seed(101)\n",
    "errors = np.random.normal(mu,sigma,size=(nsta,1))\n",
    "dobs2_delay_noise = dobs2_delay+errors"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "868a0b3e",
   "metadata": {},
   "source": [
    "# Double Difference Method"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8bd565a8",
   "metadata": {},
   "source": [
    "### Event $i$, station $k$\n",
    "The travel-time residual $r_k^i=(T_k^i)^{obs}-(T_k^i)^{cal}$ comes from:\n",
    "1. Earthquake location mistfit;\n",
    "2. Earthquake origin time misfit;\n",
    "3. Along ray-path velocity variation;\n",
    "4. Station delay.\n",
    "\n",
    "could be presented via below equation:\n",
    "$$\n",
    "r_k^i=\\sum_{l=1}^2\\frac{\\partial T_k^i}{\\partial x_l^i}\\Delta x_l^i +\\Delta\\tau^i+\\int_{s_i}^{r_k}\\Delta uds+S_k\n",
    "$$\n",
    "$k$: station;    $i$: event;  \n",
    "\n",
    "$T$: travel time\n",
    "\n",
    "$\\tau$: event origin time\n",
    "\n",
    "$s,r$: source and receiver location\n",
    "\n",
    "$u=\\frac{1}{V}$: slowness\n",
    "\n",
    "$S_k$: station delay\n",
    "### Event $j$, station $k$\n",
    "The travel-time residual $r_k^j=(T_k^j)^{obs}-(T_k^j)^{cal}$ could be presented:\n",
    "$$r_k^j=\\sum_{l=1}^2\\frac{\\partial T_k^j}{\\partial x_l^j}\\Delta x_l^j +\\Delta\\tau^j+\\int_{s_j}^{r_k}\\Delta uds+S_k$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3573775f",
   "metadata": {},
   "source": [
    "### Make difference\n",
    "$$\n",
    "r_k^i-r_k^j=\\sum_{l=1}^2\\frac{\\partial T_k^i}{\\partial x_l^i}\\Delta x_l^i +\\Delta\\tau^i+\\int_{s_i}^{r_k}\\Delta uds-\n",
    "\\sum_{l=1}^2\\frac{\\partial T_k^j}{\\partial x_l^j}\\Delta x_l^j -\\Delta\\tau^j-\\int_{s_j}^{r_k}\\Delta uds\n",
    "$$\n",
    "Noted that station delay $S$ is removed.\n",
    "\n",
    "#### Note that\n",
    "$$ r_k^i-r_k^j = \\{(T_k^i)^{obs}-(T_k^i)^{cal}\\}-\\{(T_k^j)^{obs}-(T_k^j)^{cal}\\}$$\n",
    "#### Reorganize the equation leads to\n",
    "$$r_k^i - r_k^j=(T_k^i-T_k^j)^{obs}-(T_k^i-T_k^j)^{cal}$$\n",
    "This is the so-called **double-difference**.\n",
    "\n",
    "If **two events are close** to each other, then they have similar ray paths, that is:\n",
    "$$\\int_{s_i}^{r_k}\\Delta uds \\approx \\int_{s_j}^{r_k}\\Delta uds$$\n",
    "The velocity anomaly along the ray path is the same for two events.\n",
    "#### Then we get\n",
    "$$\n",
    "r_k^i-r_k^j=\\sum_{l=1}^2\\frac{\\partial T_k^i}{\\partial x_l^i}\\Delta x_l^i+\\Delta\\tau^i-\n",
    "\\sum_{l=1}^2\\frac{\\partial T_k^j}{\\partial x_l^j}\\Delta x_l^j -\\Delta\\tau^j\n",
    "$$\n",
    "##### The travel time residual $r_k^i=(T_k^i)^{obs}-(T_k^i)^{cal}$, the travel time residual $r_k^j=(T_k^j)^{obs}-(T_k^j)^{cal}$, their difference is related to:\n",
    "    1. Earthquake location misfit\n",
    "    2. Origin time misfit\n",
    "##### and the error sources:\n",
    "    1. Station delay\n",
    "    2. along ray-path velocity variation\n",
    "##### are remove or mitigated by double-difference"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc0c0fd8",
   "metadata": {},
   "source": [
    "An inversion equation could be set up:\n",
    "$$G\\Delta m=\\Delta d$$\n",
    "Detailed expression is, note the negative signs in the last 3 columns of data kernel $\\mathbf{G}$:\n",
    "$$\n",
    "\\begin{bmatrix}\n",
    "\\frac{\\partial T_1^1}{\\partial x}&\\frac{\\partial T_1^1}{\\partial z}&1&-\\frac{\\partial T_1^2}{\\partial x}&-\\frac{\\partial T_1^2}{\\partial z}&-1\\\\\n",
    "\\frac{\\partial T_2^1}{\\partial x}&\\frac{\\partial T_2^1}{\\partial z}&1&-\\frac{\\partial T_2^2}{\\partial x}&-\\frac{\\partial T_2^2}{\\partial z}&-1\\\\\n",
    "\\vdots&\\vdots&\\vdots&\\vdots&\\vdots&\\vdots&\\\\\n",
    "\\frac{\\partial T_k^1}{\\partial x}&\\frac{\\partial T_k^1}{\\partial z}&1&-\\frac{\\partial T_k^2}{\\partial x}&-\\frac{\\partial T_k^2}{\\partial z}&-1\\\\\n",
    "\\end{bmatrix}\n",
    "\\begin{bmatrix}\n",
    "\\Delta x_1\\\\\\Delta z_1 \\\\\\Delta t_1 \\\\\\Delta x_2 \\\\\\Delta z_2 \\\\\\Delta t_2\n",
    "\\end{bmatrix}=\n",
    "\\begin{bmatrix}\n",
    "r_1^1 - r_1^2\\\\r_2^1 - r_2^2\\\\\\vdots\\\\r_k^1 - r_k^2\\\\\n",
    "\\end{bmatrix}\n",
    "$$\n",
    "Practical usage will be introduced later.\n",
    "### Workflow\n",
    "<img src=\"DD_Earthquake_location_workflow_new.jpg\" width='800'>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e87d635a",
   "metadata": {},
   "outputs": [],
   "source": [
    "hyc1_dd = hyc1_abs.copy()\n",
    "hyc2_dd = hyc2_abs.copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7019d758",
   "metadata": {},
   "source": [
    "### 1. Observed Travel Time Difference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c75dc98",
   "metadata": {},
   "outputs": [],
   "source": [
    "obs_trav_t1 = dobs1_delay - hyc1_dd[2] # Travel time = arrival_time - origin_time \n",
    "obs_trav_t2 = dobs2_delay - hyc2_dd[2]\n",
    "obs_dt = obs_trav_t1 - obs_trav_t2      "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7745fe3",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "matrix_show(obs_dt)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b1672af",
   "metadata": {},
   "source": [
    "### 2. Calculated Travel Time Difference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7c7604c",
   "metadata": {},
   "outputs": [],
   "source": [
    "dcal1 = np.zeros((nsta,1))\n",
    "for i in range(dobs1.shape[0]):\n",
    "    dx = stas[i,0]-hyc1_dd[0]\n",
    "    dz = stas[i,1]-hyc1_dd[1]\n",
    "    dcal1[i,0] = np.sqrt(dx**2+dz**2)/Vtrue+hyc1_dd[2]\n",
    "dcal2 = np.zeros((nsta,1))\n",
    "for i in range(dobs1.shape[0]):\n",
    "    dx = stas[i,0]-hyc2_dd[0]\n",
    "    dz = stas[i,1]-hyc2_dd[1]\n",
    "    dcal2[i,0] = np.sqrt(dx**2+dz**2)/Vtrue+hyc2_dd[2]\n",
    "cal_trav_t1 = dcal1 - hyc1_dd[2] # Travel time = calculated_time - origin_time \n",
    "cal_trav_t2 = dcal2 - hyc2_dd[2]\n",
    "cal_dt = cal_trav_t1 - cal_trav_t2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ead1599",
   "metadata": {},
   "source": [
    "## 3. Calculate Double-Difference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d44409d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "dtdt = obs_dt - cal_dt\n",
    "matrix_show(dtdt)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab02f7b7",
   "metadata": {},
   "source": [
    "## 4. Build Up Data Kernel - G"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5fcc0912",
   "metadata": {},
   "outputs": [],
   "source": [
    "ncol = 3 * 2           # Two event, each has 3 parameter (delta x, delta z, delta t)\n",
    "G = np.zeros((nsta,ncol))\n",
    "G[:,2]=1; G[:,5] = -1   # Partial derivative of origin column is 1\n",
    "for i in range(nsta):\n",
    "    for j in range(2):\n",
    "        denomiter1 = np.sqrt((hyc1_dd[0]-stas[i,0])**2+(hyc1_dd[1]-stas[i,1])**2)\n",
    "        G[i,j]=(hyc1_dd[j]-stas[i,j])/denomiter1/Vtrue\n",
    "        denomiter2 = np.sqrt((hyc2_dd[0]-stas[i,0])**2+(hyc2_dd[1]-stas[i,1])**2)\n",
    "        G[i,j+3]=-(hyc2_dd[j]-stas[i,j])/denomiter2/Vtrue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34db95c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "matrix_show(G)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f071b3df",
   "metadata": {},
   "source": [
    "## 5. Check GTG Inverse Exists\n",
    "$$G\\Delta m =\\Delta d$$\n",
    "$G$ is not a square matrix, $G^TG$ is a squared matrix, we then have:\n",
    "$$G^TG\\Delta m=G^T\\Delta d$$\n",
    "If the inverse of $G^TG$ exists (the determinnant != 0, in here we have 10 observations to solve for 4 parameters), then:\n",
    "$$\\Delta m = (G^TG)^{-1}G^T\\Delta d$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f00cd85",
   "metadata": {},
   "outputs": [],
   "source": [
    "GTG = np.matmul(G.T,G)\n",
    "det = np.linalg.det(GTG)  # Calculate matrix determinant\n",
    "if det == 0:\n",
    "    print(\"Error! The determinant is ZERO!!!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6083875c",
   "metadata": {},
   "source": [
    "## 6. Add Damp to Matrix\n",
    "Determinant equals zero means there is no unique solution to the inverse problem, that is, the constraints in data kernel G is not enough to get a result, more constraints is needed. The common method is to add damp to the data kernel.\n",
    "### Damping the kernel\n",
    "Before damping:\n",
    "$$\\begin{bmatrix}G\\end{bmatrix}\\begin{bmatrix}m\\end{bmatrix}=\\begin{bmatrix}d\\end{bmatrix}$$\n",
    "After damping:\n",
    "$$\\begin{bmatrix}G\\\\\\lambda I\\end{bmatrix}\\begin{bmatrix}m\\end{bmatrix}=\\begin{bmatrix}d\\\\O\\end{bmatrix}$$\n",
    "$I$ is an identity matrix, in this case, it should have columns with G, so its dimension is $6\\times6$, here:\n",
    "$$I=\\begin{bmatrix}\n",
    "\\lambda&0&0&0&0&0\\\\\n",
    "0&\\lambda&0&0&0&0\\\\\n",
    "0&0&\\lambda&0&0&0\\\\\n",
    "0&0&0&\\lambda&0&0\\\\\n",
    "0&0&0&0&\\lambda&0\\\\\n",
    "0&0&0&0&0&\\lambda\\\\\n",
    "\\end{bmatrix}$$\n",
    "### Mathematical Meaning\n",
    "Write new constraints in equation, that is:\n",
    "$$\n",
    "\\begin{align}\n",
    "\\lambda\\Delta x_1 &= 0\\\\ \\lambda\\Delta z_1 &= 0\\\\ \\lambda\\Delta t_1 &= 0\\\\ \\lambda\\Delta x_2 &= 0\\\\ \\lambda\\Delta z_2 &= 0\\\\ \\lambda\\Delta t_2 &= 0\n",
    "\\end{align}\n",
    "$$\n",
    "What does this mean? It means that the solution **SHOULD** be zero. As least square problem solution is a trade-off among equations, The application of damping factor will lead to the solution be small values. $\\lambda$ controls the weight(importance) of damping. A large damp will lead to the solution more close to zero."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60ffd46a",
   "metadata": {},
   "outputs": [],
   "source": [
    "G_dp = np.zeros((nsta+ncol,ncol))\n",
    "G_dp[:nsta,:] = G\n",
    "damp = 0.1\n",
    "G_dp[nsta:,:] = np.diag([1,1,1,1,1,1])*damp\n",
    "dtdt_damp = np.zeros((nsta+ncol,1))\n",
    "dtdt_damp[:nsta,0] = dtdt.ravel()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aabe7db0",
   "metadata": {},
   "outputs": [],
   "source": [
    "matrix_show(G_dp)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f24df550",
   "metadata": {},
   "source": [
    "## 7. Solve Damped Problem\n",
    "Step 1:\n",
    "$$\\begin{bmatrix}G\\\\\\lambda I\\end{bmatrix}\\begin{bmatrix}m\\end{bmatrix}=\\begin{bmatrix}d\\\\O\\end{bmatrix}$$\n",
    "Step 2:\n",
    "$$\n",
    "\\begin{bmatrix}G^T\\lambda I\\end{bmatrix}\n",
    "\\begin{bmatrix}G\\\\\\lambda I\\end{bmatrix}\n",
    "\\begin{bmatrix}m\\end{bmatrix}\n",
    "=\n",
    "\\begin{bmatrix}G^T\\lambda I\\end{bmatrix}\n",
    "\\begin{bmatrix}d\\\\O\\end{bmatrix}\n",
    "$$\n",
    "Step 3:\n",
    "$$\n",
    "\\begin{bmatrix}G^TG+\\lambda^2 I\\end{bmatrix}\n",
    "\\begin{bmatrix}m\\end{bmatrix}\n",
    "=\n",
    "\\begin{bmatrix}G^Td\\end{bmatrix}\n",
    "$$\n",
    "Step 4:\n",
    "$$\n",
    "m=(G^TG+\\lambda^2 I)^{-1}G^Td\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29b86b59",
   "metadata": {},
   "outputs": [],
   "source": [
    "G_dpTG_dp = np.matmul(G_dp.T,G_dp)\n",
    "G_dpTG_dp_inv = np.linalg.inv(G_dpTG_dp)\n",
    "G_dpTG_dp_inv_G_dpT = np.matmul(G_dpTG_dp_inv,G_dp.T)\n",
    "m = np.matmul(G_dpTG_dp_inv_G_dpT,dtdt_damp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c37f0209",
   "metadata": {},
   "outputs": [],
   "source": [
    "matrix_show(m)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2dfdae4a",
   "metadata": {},
   "source": [
    "## 8. Update Location\n",
    "\n",
    "The output results are the earthquake location misfit with reference to its absolute location. Therefore, the absolute earthquake location should be updated.\n",
    "\n",
    "$$x_1 = x_1+\\Delta x_1$$\n",
    "$$z_1 = z_1+\\Delta z_1$$\n",
    "$$t_1 = t_1+\\Delta t_1$$\n",
    "$$x_2 = x_2+\\Delta x_2$$\n",
    "$$z_2 = z_2+\\Delta z_2$$\n",
    "$$t_2 = t_2+\\Delta t_2$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10259c18",
   "metadata": {},
   "outputs": [],
   "source": [
    "hyc1_dd = hyc1_dd+m.ravel()[:3]\n",
    "hyc2_dd = hyc2_dd+m.ravel()[3:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8fe6f132",
   "metadata": {},
   "outputs": [],
   "source": [
    "xmin = min(hyc1_true[0],hyc1_abs[0],hyc1_dd[0])\n",
    "xmax = max(hyc1_true[0],hyc1_abs[0],hyc1_dd[0])\n",
    "ymin = min(hyc1_true[1],hyc1_abs[1],hyc1_dd[1])\n",
    "ymax = max(hyc1_true[1],hyc1_abs[1],hyc1_dd[1])\n",
    "plt.plot(hyc1_true[0],hyc1_true[1],\"bo\",label=\"Event 1 true location\")\n",
    "plt.plot(hyc2_true[0],hyc2_true[1],\"ro\",label=\"Event 2 true location\")\n",
    "plt.plot(hyc1_abs[0],hyc1_abs[1],'bx',label=\"Event 1 absolute location\")\n",
    "plt.plot(hyc2_abs[0],hyc2_abs[1],'rx',label=\"Event 2 absolute location\")\n",
    "plt.plot(hyc1_dd[0],hyc1_dd[1],'b*',label=\"Event 1 dd location\")\n",
    "plt.plot(hyc2_dd[0],hyc2_dd[1],'r*',label=\"Event 2 dd location\")\n",
    "plt.gca().set_aspect('equal')\n",
    "plt.legend()\n",
    "plt.ylim(ymax+0.5,ymin-0.5)\n",
    "plt.ylabel(\"Depth (km)\")\n",
    "plt.xlabel(\"X (km)\");"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f75e61d0",
   "metadata": {},
   "source": [
    "## 9. Error analysis\n",
    "The error in observed data will of couse lead to uncertainties in the earthquake location parameters estimation. Their relationship could be described as:\n",
    "$$\\sigma_m^2=\\sigma^2(G^TG+\\lambda^2 I)^{-1}$$\n",
    "(Wanna know how is this relationship derived? Please refer to page 435 of **An Introduction to Seismology, Earthquakes, and Earth Structure**)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4e4d1a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "mean_dtdt_damp = np.mean(dtdt_damp)\n",
    "e2 = 0\n",
    "for i in range(dtdt.shape[0]):\n",
    "    e2 += (dtdt_damp[i,0] - mean_dtdt_damp)**2\n",
    "print(f\"Square error: \",format(e2,'13.8f'))\n",
    "var = e2/(dtdt_damp.shape[0]-6)\n",
    "sigma_m2 = G_dpTG_dp_inv*var"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77e7757d",
   "metadata": {},
   "outputs": [],
   "source": [
    "present_loc_results(hyc1_dd,sigma_m2[:3,:3])\n",
    "present_loc_results(hyc2_dd,sigma_m2[3:,3:])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02724e3d",
   "metadata": {},
   "source": [
    "## Exercise (5 min)\n",
    "Try to modify the **damp** parameter and update the results, how it changes? What is the relationship between **damping factor**, **m**, and **Uncertainty**? Can you explain why?\n",
    "<br />\n",
    "<br />\n",
    "<br />\n",
    "<br />\n",
    "<br />"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52cad006",
   "metadata": {},
   "source": [
    "## 10. Condition Number\n",
    "We have realized that the damping factor controls the converge rate, a larger **damping factor** will lead to slow converge rate but small uncertainty; a smaller **damping factor** will lead to fast converge rate but large uncertainty. Then how to choose proper damping factor?\n",
    "\n",
    "A good indicator is the **[conditon number](https://en.wikipedia.org/wiki/Condition_number)**. Conditon number quantifies the relationship between solution error and data error. In earthquake double difference location, the condition number should be in the range 40-100 (empirical)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "415e4465",
   "metadata": {},
   "outputs": [],
   "source": [
    "cond = np.linalg.cond(G_dp)\n",
    "print(\"Condtion number is: \",format(cond,'.2f'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "260c0208",
   "metadata": {},
   "source": [
    "### Exercise: Start Another Iteration\n",
    "The error is still high, update the earthquake location and rerun the process to check the location variation.\n",
    "<br />\n",
    "<br />\n",
    "<br />\n",
    "<br />\n",
    "<br />"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04b3f8c9",
   "metadata": {},
   "source": [
    "# Iterative Double-Difference Method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b33c557b",
   "metadata": {},
   "outputs": [],
   "source": [
    "hyc1_loop = hyc1_abs\n",
    "hyc2_loop = hyc2_abs\n",
    "niter = 100\n",
    "k = 0\n",
    "event_number = 2\n",
    "event_parameters = 3 #(x,y,z)\n",
    "#----------Iteration starts----------------------\n",
    "while k <=niter:\n",
    "    #----1. Update observed travel time difference------------------\n",
    "    obs_trav_t1 = dobs1_delay - hyc1_dd[2]               # Travel time = arrival_time - origin_time \n",
    "    obs_trav_t2 = dobs2_delay - hyc2_dd[2]\n",
    "    obs_dt = obs_trav_t1 - obs_trav_t2    \n",
    "    #----2. Update calculated travel time difference------------------\n",
    "    dcal1 = np.zeros((dobs1.shape[0],1))\n",
    "    for i in range(dobs1.shape[0]):\n",
    "        dx = stas[i,0]-hyc1_loop[0]\n",
    "        dz = stas[i,1]-hyc1_loop[1]\n",
    "        dcal1[i,0] = np.sqrt(dx**2+dz**2)/Vtrue+hyc1_loop[2]\n",
    "    dcal2 = np.zeros((dobs2.shape[0],1))\n",
    "    for i in range(dobs1.shape[0]):\n",
    "        dx = stas[i,0]-hyc2_loop[0]\n",
    "        dz = stas[i,1]-hyc2_loop[1]\n",
    "        dcal2[i,0] = np.sqrt(dx**2+dz**2)/Vtrue+hyc2_loop[2]\n",
    "    cal_trav_t1 = dcal1 - hyc1_dd[2] \n",
    "    cal_trav_t2 = dcal2 - hyc2_dd[2]\n",
    "    cal_dt = cal_trav_t1 - cal_trav_t2\n",
    "    #----3. Calculate double difference-------------------------------\n",
    "    dtdt = obs_dt - cal_dt\n",
    "    #----4. Set up G kernel-------------------------------------------\n",
    "    ncol = event_number * event_parameters           \n",
    "    G = np.zeros((nsta,ncol))\n",
    "    G[:,2]=1; G[:,5] = -1   # Partial derivative of origin column is 1\n",
    "    for i in range(nsta):\n",
    "        for j in range(2):\n",
    "            denomiter1 = np.sqrt((hyc1_loop[0]-stas[i,0])**2+(hyc1_loop[1]-stas[i,1])**2)\n",
    "            G[i,j]=(hyc1_loop[j]-stas[i,j])/denomiter1/Vtrue\n",
    "            denomiter2 = np.sqrt((hyc2_loop[0]-stas[i,0])**2+(hyc2_loop[1]-stas[i,1])**2)\n",
    "            G[i,j+3]=-(hyc2_loop[j]-stas[i,j])/denomiter2/Vtrue\n",
    "    #----5. Add damp--------------------------------------------------\n",
    "    G_dp = np.zeros((nsta+ncol,ncol))\n",
    "    G_dp[:nsta,:] = G\n",
    "    damp = 0.1\n",
    "    G_dp[nsta:,:] = np.diag([1,1,1,1,1,1])*damp\n",
    "    dtdt_damp = np.zeros((nsta+ncol,1))\n",
    "    dtdt_damp[:nsta,0] = dtdt.ravel()\n",
    "    #----6. Solve for Solution-----------------------------------------\n",
    "    G_dpTG_dp = np.matmul(G_dp.T,G_dp)\n",
    "    G_dpTG_dp_inv = np.linalg.inv(G_dpTG_dp)\n",
    "    G_dpTG_dp_inv_G_dpT = np.matmul(G_dpTG_dp_inv,G_dp.T)\n",
    "    m = np.matmul(G_dpTG_dp_inv_G_dpT,dtdt_damp)\n",
    "    #----7. Update location-----------------------------------------------\n",
    "    hyc1_loop = hyc1_loop+m.ravel()[:3]\n",
    "    hyc2_loop = hyc2_loop+m.ravel()[3:]\n",
    "    #----8. Error Calculation------------------------------------------------\n",
    "    mean_dtdt_damp = np.mean(dtdt_damp)\n",
    "    e2 = 0\n",
    "    for i in range(dtdt.shape[0]):\n",
    "        e2 += (dtdt_damp[i,0] - mean_dtdt_damp)**2\n",
    "    print(f\"Iteration {format(k,'4d')} square error: \",format(e2,'13.8f'))\n",
    "    if e2<0.0000000001:\n",
    "        print(\"Itertion stopped for too small error!\")\n",
    "        break\n",
    "    k = k+1\n",
    "#--------9. Variance analysis-------------------------------------------\n",
    "var = e2/(dtdt_damp.shape[0]-event_number * event_parameters)\n",
    "sigma_m2 = G_dpTG_dp_inv*var\n",
    "hyc1_dd = hyc1_loop\n",
    "hyc2_dd = hyc2_loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c52df97",
   "metadata": {},
   "outputs": [],
   "source": [
    "present_loc_results(hyc1_dd,sigma_m2[:3,:3],std_fmt='.5f')\n",
    "present_loc_results(hyc2_dd,sigma_m2[3:,3:],std_fmt='.5f')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7391eb08",
   "metadata": {},
   "source": [
    "# LSQR Algorithm"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d63fb0d6",
   "metadata": {},
   "source": [
    "## Large matrix, its inverse and SVD\n",
    "Considering a double difference cluster with 1000 events, we estimate the time consumed for one iteration. Note the $G^TG$ dimension is $4000\\times 4000$, it costs 16 seconds to calculate the inverse and singular value decomposition. What about 10 k events?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77872354",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "G = np.random.randn(4000,4000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4570f9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "tmp1 = time.time()\n",
    "G_inv = np.linalg.inv(G)\n",
    "u,s,vt = np.linalg.svd(G_inv)\n",
    "tmp2 = time.time()\n",
    "print(tmp2-tmp1,' s')\n",
    "if (tmp2-tmp1)>5:\n",
    "    print(\"Wow, it cost a lot of time of do the calculation\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3564b39d",
   "metadata": {},
   "source": [
    "## Introduction to LSQR\n",
    "Least-Square QR decompositon (LSQR, [*Paige, C.C and Saunders, M.A. (1982)*](https://dl.acm.org/doi/pdf/10.1145/355984.355989)) method is developed for least-square solution for large dataset, its performance in ill-conditioned problems is superior.\n",
    "\n",
    "From problem $\\mathbf{Am=b}$, $\\mathbf{A}$ maps the solution to the data space. $\\mathbf{A^T}$ maps the data to the solution space. LSQR method eliminates residual iteratively with limited computation.\n",
    "<img src='space_mapping.png' width='400'/>\n",
    "To ensure the stability of method, each A column is required to be scaled up to be unit value. That is:\n",
    "$$\n",
    "\\begin{aligned}\n",
    "\\mathbf{Am} &= \\begin{bmatrix}A_1&A_2&\\cdots&A_k\\end{bmatrix}\\begin{bmatrix}m_1\\\\m_2\\\\\\vdots\\\\m_k\\end{bmatrix}\\\\&=\n",
    "A_1m_1+A_2m_2+\\cdots+A_km_k \\\\&= \\frac{A_1}{\\|A_1\\|}(\\|A_1\\|m_1)+\\frac{A_2}{\\|A_2\\|}(\\|A_2\\|m_2)+\\cdots+\\frac{A_k}{\\|A_k\\|}(\\|A_k\\|m_k)\\\\&=\\mathbf{A'm'=b}\n",
    "\\end{aligned}\n",
    "$$\n",
    "After get the solution, a conversion between $\\mathbf{m'}$ and $\\mathbf{m}$ is needed by $m_i=\\frac{m'_i}{\\|A_i\\|}$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1a27142",
   "metadata": {},
   "outputs": [],
   "source": [
    "hyc1_loop = hyc1_abs\n",
    "hyc2_loop = hyc2_abs\n",
    "niter = 100\n",
    "k = 0\n",
    "event_number = 2\n",
    "event_parameters = 3 #(x,y,z)\n",
    "#----------Iteration starts----------------------\n",
    "while k <=niter:\n",
    "    #----1. Update observed travel time difference------------------\n",
    "    obs_trav_t1 = dobs1_delay - hyc1_dd[2]               # Travel time = arrival_time - origin_time \n",
    "    obs_trav_t2 = dobs2_delay - hyc2_dd[2]\n",
    "    obs_dt = obs_trav_t1 - obs_trav_t2    \n",
    "    #----2. Update calculated travel time difference------------------\n",
    "    dcal1 = np.zeros((dobs1.shape[0],1))\n",
    "    for i in range(dobs1.shape[0]):\n",
    "        dx = stas[i,0]-hyc1_loop[0]\n",
    "        dz = stas[i,1]-hyc1_loop[1]\n",
    "        dcal1[i,0] = np.sqrt(dx**2+dz**2)/Vtrue+hyc1_loop[2]\n",
    "    dcal2 = np.zeros((dobs2.shape[0],1))\n",
    "    for i in range(dobs1.shape[0]):\n",
    "        dx = stas[i,0]-hyc2_loop[0]\n",
    "        dz = stas[i,1]-hyc2_loop[1]\n",
    "        dcal2[i,0] = np.sqrt(dx**2+dz**2)/Vtrue+hyc2_loop[2]\n",
    "    cal_trav_t1 = dcal1 - hyc1_dd[2] \n",
    "    cal_trav_t2 = dcal2 - hyc2_dd[2]\n",
    "    cal_dt = cal_trav_t1 - cal_trav_t2\n",
    "    #----3. Calculate double difference-------------------------------\n",
    "    dtdt = obs_dt - cal_dt\n",
    "    #----4. Set up G kernel-------------------------------------------\n",
    "    ncol = event_number * event_parameters           \n",
    "    G = np.zeros((nsta,ncol))\n",
    "    G[:,2]=1; G[:,5] = -1   # Partial derivative of origin column is 1\n",
    "    for i in range(nsta):\n",
    "        for j in range(2):\n",
    "            denomiter1 = np.sqrt((hyc1_loop[0]-stas[i,0])**2+(hyc1_loop[1]-stas[i,1])**2)\n",
    "            G[i,j]=(hyc1_loop[j]-stas[i,j])/denomiter1/Vtrue\n",
    "            denomiter2 = np.sqrt((hyc2_loop[0]-stas[i,0])**2+(hyc2_loop[1]-stas[i,1])**2)\n",
    "            G[i,j+3]=-(hyc2_loop[j]-stas[i,j])/denomiter2/Vtrue\n",
    "    #---- Scale up G columns to unit length--------------------------\n",
    "    Gnorms = np.zeros(ncol)\n",
    "    for i in range(ncol):\n",
    "        norm = np.linalg.norm(G[:,i])\n",
    "        Gnorms[i] = norm\n",
    "        G[:,i] = G[:,i]/norm\n",
    "    #----6. LSQR and rescale solution---------------------------------\n",
    "    damp = 0.1\n",
    "    A = csc_matrix(G, dtype=float)\n",
    "    m,istop,itn,r1norm,r2norm,anorm,acond,arnorm,xnorm,var=lsqr(A,dtdt,damp=damp,calc_var=True)\n",
    "    m = np.divide(m,Gnorms)\n",
    "    var = np.divide(var,Gnorms**2)\n",
    "    #----7. Update location-----------------------------------------------\n",
    "    hyc1_loop = hyc1_loop+m.ravel()[:3]\n",
    "    hyc2_loop = hyc2_loop+m.ravel()[3:]\n",
    "    #----8. Error Calculation------------------------------------------------\n",
    "    print(f\"Iteration {format(k,'4d')} residual: \",format(r1norm,'13.8f'))\n",
    "    if r1norm<0.0000000001:\n",
    "        print(\"Itertion stopped for too small error!\")\n",
    "        break\n",
    "    k = k+1\n",
    "#--------9. Variance analysis-------------------------------------------\n",
    "sigma_m2 = np.diag(var)**2*r2norm**2\n",
    "hyc1_dd = hyc1_loop\n",
    "hyc2_dd = hyc2_loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "696532ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "xmin = min(hyc1_true[0],hyc1_abs[0],hyc1_dd[0])\n",
    "xmax = max(hyc1_true[0],hyc1_abs[0],hyc1_dd[0])\n",
    "ymin = min(hyc1_true[1],hyc1_abs[1],hyc1_dd[1])\n",
    "ymax = max(hyc1_true[1],hyc1_abs[1],hyc1_dd[1])\n",
    "plt.plot(hyc1_true[0],hyc1_true[1],\"bo\",label=\"Event 1 true location\")\n",
    "plt.plot(hyc2_true[0],hyc2_true[1],\"ro\",label=\"Event 2 true location\")\n",
    "plt.plot(hyc1_abs[0],hyc1_abs[1],'bx',label=\"Event 1 absolute location\")\n",
    "plt.plot(hyc2_abs[0],hyc2_abs[1],'rx',label=\"Event 2 absolute location\")\n",
    "plt.plot(hyc1_dd[0],hyc1_dd[1],'*',color='green',label=\"Event 1 dd location\")\n",
    "plt.plot(hyc2_dd[0],hyc2_dd[1],'*',color='k',label=\"Event 2 dd location\")\n",
    "plt.gca().set_aspect('equal')\n",
    "plt.legend()\n",
    "\n",
    "plt.ylim(ymax+0.5,ymin-0.5)\n",
    "plt.ylabel(\"Depth (km)\")\n",
    "plt.xlabel(\"X (km)\");"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9fbd4e12",
   "metadata": {},
   "outputs": [],
   "source": [
    "present_loc_results(hyc1_dd,sigma_m2[:3,:3],std_fmt='.8f')\n",
    "present_loc_results(hyc2_dd,sigma_m2[3:,3:],std_fmt='.8f')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c88724e",
   "metadata": {},
   "source": [
    "# Summary\n",
    "In this tutorial, we first demonstrate the influence of velocity misfit and **Station delay**'s influence on earthquake location results.\n",
    "\n",
    "We then introduce the double-difference method, which theoritical diminishes the station delay and limit the influence of veloctity misfit. During processing, we:\n",
    "   * Set up the data kernel **G** and calculate the double difference array **dtdt**\n",
    "   * Add damping to the data kernel to make it stable (*determinant not be zero*)\n",
    "   * Use **conditon number** to guide the selection of damping factor\n",
    "   * Comparison shows **double-difference** method leads to location with **better performance**\n",
    " \n",
    "**Notes**\n",
    "\n",
    "*we use one-layer velocity model for the convenience in finding the ray partial derivatives.*"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a6721dd",
   "metadata": {},
   "source": [
    "# Homework\n",
    "1. In the demo example, is event origin time fully recovered? Could you please explain the reason?(10 points)\n",
    "2. Note we add negative symbol to partial derivatives of the event 2 in constructing the data kernel, do you know why? (10 points)\n",
    "3. In calculating the variance(**var**), it is written ```var = e2/(dtdt_damp.shape[0]-event_number * event_parameters)```, do you know why variance is different from square error here? (10 points)\n",
    "3. Add one more event hyc_true3 = (0.2,8.1,1) (x,z,t) and prepare for inversion, set up suitable damping factor so that conditon number in the range 40-100.(80 points)\n",
    "   * Show the absolute location result of the newly added event and its uncertainty. (20 points)\n",
    "   * Show your data kernel G for Double-Difference inversion and its determinant. (20 points)\n",
    "   * Show your Double-Difference inversion result and its uncertainty, how many iterations you used? (20 points)\n",
    "   * Did your results get closer to true earthquake locations? Make a plot and show (20 points)\n",
    "   #### Hint\n",
    "   The dimension of $m$ should be $9 \\times 1$\n",
    "   $$m^T = \\begin{bmatrix}\n",
    "       \\Delta x_1&\\Delta z_1&\\Delta t_1 &\n",
    "       \\Delta x_2&\\Delta z_2&\\Delta t_2 &\n",
    "       \\Delta x_3&\\Delta z_3&\\Delta t_3 \n",
    "   \\end{bmatrix}$$\n",
    "   For the double-difference value of event_1 and event_2 recorded in station k, its corresponding row of data kernel G should be:\n",
    "   $$\\begin{bmatrix}\n",
    "       \\frac{\\partial T^{1}_{k}}{\\partial x}&\\frac{\\partial T^{1}_{k}}{\\partial z}&\\frac{\\partial T^{1}_{k}}{\\partial t}&\n",
    "       -\\frac{\\partial T^{2}_{k}}{\\partial x}&-\\frac{\\partial T^{2}_{k}}{\\partial z}&-\\frac{\\partial T^{2}_{k}}{\\partial t}&\n",
    "       0&0&0\n",
    "   \\end{bmatrix}$$\n",
    "   For the double-difference value of event_2 and event_3 recorded in station k, its corresponding row of data kernel G should be:\n",
    "   $$\\begin{bmatrix}\n",
    "       0&0&0&\n",
    "       \\frac{\\partial T^{2}_{k}}{\\partial x}&\\frac{\\partial T^{2}_{k}}{\\partial z}&\\frac{\\partial T^{2}_{k}}{\\partial t}&\n",
    "       -\\frac{\\partial T^{3}_{k}}{\\partial x}&-\\frac{\\partial T^{3}_{k}}{\\partial z}&-\\frac{\\partial T^{3}_{k}}{\\partial t}\n",
    "   \\end{bmatrix}$$"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
